#####################################################################################################################
#
# File: config/calvalus.properties
#
# Read by com.bc.calvalus.portal.server.BackendConfig.
# Properties in this file may be overridden by Java System properties.
#
# A parameter of format "calvalus.hadoop.<name>" will become a Hadoop job configuration properties "<name>".
#
#####################################################################################################################

# Factory that instantiates the production service.
# calvalus.portal.productionServiceFactory.class=com.bc.calvalus.production.local.LocalProductionServiceFactory
calvalus.portal.productionServiceFactory.class = com.bc.calvalus.production.hadoop.HadoopServiceContainerFactory

# optional location for production DB and user regions
# default is ~/.calvalus
calvalus.portal.appDataDir = /home/cvop/.calbigfe

# optional path of archive root, location of product-sets.csv
# absolute or relative to /calvalus , default eodata
calvalus.portal.archiveRootDir = /calvalus/projects/bigfe/archive

# optional path of software bundles dir
# default is /calvalus/software/1.0
calvalus.portal.softwareDir = /calvalus/projects/bigfe/software

# portal access control and visual configuration
# for each view or feature list the user roles entitled to see it
calvalus.portal.userRole = calbigfe bc
calvalus.portal.newsView =
calvalus.portal.l2View = calbigfe bc
calvalus.portal.maView = bc
calvalus.portal.raView =
calvalus.portal.l3View = calbigfe bc
calvalus.portal.taView =
calvalus.portal.masksView =
calvalus.portal.freshmonView =
calvalus.portal.bootstrappingView =
calvalus.portal.vicariousCalibrationView =
calvalus.portal.matchupComparisonView =
calvalus.portal.l2ToL3ComparisonView =
calvalus.portal.regionsView = calbigfe bc
calvalus.portal.bundlesView =
calvalus.portal.requestsView = calbigfe bc
calvalus.portal.productionsView = calbigfe bc
calvalus.portal.otherSets = calbigfe bc
calvalus.portal.catalogue =
calvalus.portal.unlimitedJobSize =

# Output file staging directory.
# Value is relative to the context's directory
calvalus.portal.staging.path = staging

# File upload directory (not yet used).
# Value is relative to the context's directory
calvalus.portal.upload.path = uploads

# Hadoop HDFS locator "fs.default.name"
#calvalus.hadoop.fs.defaultFS = hdfs://master00:9000
calvalus.hadoop.fs.defaultFS = hdfs://calvalus
calvalus.hadoop.dfs.nameservices = calvalus
calvalus.hadoop.dfs.ha.namenodes.calvalus = nn1,nn2
calvalus.hadoop.dfs.namenode.rpc-address.calvalus.nn1 = master00:8020
calvalus.hadoop.dfs.namenode.rpc-address.calvalus.nn2 = master01:8020
calvalus.hadoop.dfs.client.failover.proxy.provider.calvalus = org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

# Hadoop namenode locator "mapred.job.tracker"
#calvalus.hadoop.yarn.resourcemanager.address = master00:8032

# accepted failure percentage
calvalus.hadoop.mapreduce.map.failures.maxpercent = 5

# Calvalus software bundle "calvalus.calvalus.bundle"
calvalus.hadoop.calvalus.calvalus.bundle = calvalus-2.22

# BEAM/SNAP software bundle "calvalus.snap.bundle"
calvalus.hadoop.calvalus.snap.bundle = snap-8.6cv

calvalus.hadoop.mapreduce.framework.name = yarn
#calvalus.hadoop.yarn.resourcemanager.hostname = master00
calvalus.hadoop.yarn.resourcemanager.ha.enabled = true
calvalus.hadoop.yarn.resourcemanager.cluster-id = calvalus-yarn
calvalus.hadoop.yarn.resourcemanager.ha.rm-ids = rm1,rm2
calvalus.hadoop.yarn.resourcemanager.hostname = master00
calvalus.hadoop.yarn.resourcemanager.hostname.rm1 = master00
calvalus.hadoop.yarn.resourcemanager.hostname.rm2 = master01
calvalus.hadoop.yarn.client.failover-proxy-provider = org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider

calvalus.hadoop.mapreduce.jobhistory.address = master00:10200
calvalus.hadoop.mapreduce.jobhistory.webapp.address = master00:19888

# for Windows developer debugging the portal this may be necessary
calvalus.hadoop.mapreduce.app-submission.cross-platform = true

# optional production queue to submit jobs to when using the portal
# default is default
calvalus.hadoop.mapreduce.job.queuename = dcs4cop
calvalus.queue.bc = dcs4cop test
calvalus.queue.bigfe = dcs4cop

